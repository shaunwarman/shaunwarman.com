(window.webpackJsonp=window.webpackJsonp||[]).push([[4],{28:function(e,a,t){"use strict";t.r(a);var s=t(0),n=function(e){var a,t,s,n=(s=void 0,(a={}).type=t="post",a.internal=s,a.contentType="markdown",a.slug="understanding-docker-images",a.content=s,a.createdAt=new Date(15299712e5),a.updatedAt=new Date(1585948589270),a.title="Understanding docker images",a.date="2018-06-26",a.layout=t,a.markdownHeadings=[{text:"Image layers",slug:"image-layers",level:2},{text:"Build time",slug:"build-time",level:3},{text:"Deploy time",slug:"deploy-time",level:3},{text:"Keep it light",slug:"keep-it-light",level:2},{text:"Conclusion",slug:"conclusion",level:2}],a.excerpt='<p><img src="https://miro.medium.com/max/1400/0*Ld_q9vnfpV5ZVRFe" alt=""></p>\n',a.permalink="/posts/understanding-docker-images.html",a.assets={},a.attributes=a,a),i=e.options.beforeCreate||[];e.options.beforeCreate=[function(){this.$page=n}].concat(i);["layout","transition"].forEach((function(a){var t=e.options.PageComponent;t&&(e.options[a]=t[a]),void 0===e.options[a]&&(e.options[a]=n[a])})),n.slug&&(e.options.name="page-wrapper-"+n.slug.replace(/[^0-9a-z\-]/gi,"-"))},i=Object(s.a)({},(function(){var e=this,a=e.$createElement,t=e._self._c||a;return t("layout-manager",[t("p",[t("img",{attrs:{src:"https://miro.medium.com/max/1400/0*Ld_q9vnfpV5ZVRFe",alt:""}})]),e._v(" "),t("p",[e._v("TLDR;")]),e._v(" "),t("ul",[t("li",[e._v("Minimize the amount of image layers")]),e._v(" "),t("li",[e._v("Use image layer cache correctly")]),e._v(" "),t("li",[e._v("Take advantage of image layers at deploy time")]),e._v(" "),t("li",[e._v("Keep images as light as possible")])]),e._v(" "),t("h2",{attrs:{id:"image-layers"}},[e._v("Image layers")]),e._v(" "),t("p",[e._v("Each docker image you use to start a container is really a cohesive set of smaller image layers. When you build your images, it’s important to understand how these layers will be used at build and deploy time.")]),e._v(" "),t("h3",{attrs:{id:"build-time"}},[e._v("Build time")]),e._v(" "),t("p",[e._v("To build an image, you use a Dockerfile with a set of instructions of what to do to build that image. Each instruction is, essentially, an image layer. Each image layer could be copying a file or directory or a command or set of commands. Here’s a simple example.")]),e._v(" "),t("div",{pre:!0,attrs:{class:"saber-highlight","data-lang":"sh"}},[t("pre",{pre:!0,attrs:{class:"saber-highlight-code language-sh"}},[t("code",{pre:!0,attrs:{class:"language-sh"}},[e._v('FROM node:10.7.0-alpine\n\nWORKDIR /usr/src/app\n\nCOPY package*.json /usr/src/app/\n\nRUN npm install && \\\n    npm cache clean -f\n\nCOPY . .\n\nCMD ["/bin/bash", "/usr/src/app/init"]')])])]),t("p",[e._v("Above is our example Dockerfile. It has a base image for nodejs that is an alpine flavor. We setup a working directory, copy files and run some commands. We also have a command that runs when a container is started from this image. Now, why would we not just copy all the files instead of splitting that into 2 copy sections? Let’s build an image from this Dockerfile and see what docker is doing.")]),e._v(" "),t("blockquote",[t("p",[e._v("$ docker build -t node:latest .")])]),e._v(" "),t("div",{pre:!0,attrs:{class:"saber-highlight","data-lang":"sh"}},[t("pre",{pre:!0,attrs:{class:"saber-highlight-code language-sh"}},[t("code",{pre:!0,attrs:{class:"language-sh"}},[e._v('Step 1/6 : FROM node:10.7.0-alpine\n ---\x3e 27d9cbdc7319\nStep 2/6 : WORKDIR /usr/src/app\n ---\x3e Using cache\n ---\x3e b738b82730f9\nStep 3/6 : COPY package*.json /usr/src/app/\n ---\x3e Using cache\n ---\x3e e50e35f227ce\nStep 4/6 : RUN npm install &&     npm cache clean --force\n ---\x3e Using cache\n ---\x3e a9f846b4f00b\nStep 5/6 : COPY . .\n ---\x3e Using cache\n ---\x3e c0abb68127bb\nStep 6/6 : CMD ["/bin/bash", "/usr/src/app/init"]\n ---\x3e Using cache\n ---\x3e 22596d178dbe\nSuccessfully built 22596d178dbe\nSuccessfully tagged node:latest')])])]),t("p",[e._v("Docker takes the Dockerfile instructions and the files in the directory, and runs through each command step-by-step, building an image layer for each command. If we look above at our Dockerfile, we have six instructions and accordingly in the build output we have six steps or image layers. As you can see below each step, there is a hash. This hash is based on the command or the files that are copied in. If the command or file changes, the hash changes, therefore, busting the cache. If the cache is busted at any step, then that step and any step after that will not be cached. Let’s take a look at each image layer created from this build.")]),e._v(" "),t("blockquote",[t("p",[e._v("$ docker history node:latest")])]),e._v(" "),t("div",{pre:!0,attrs:{class:"saber-highlight","data-lang":"sh"}},[t("pre",{pre:!0,attrs:{class:"saber-highlight-code language-sh"}},[t("code",{pre:!0,attrs:{class:"language-sh"}},[e._v('IMAGE               CREATED             CREATED BY                                      SIZE\n22596d178dbe        40 hours ago        /bin/sh -c #(nop)  CMD ["/bin/bash" "/usr/sr…   0B\nc0abb68127bb        40 hours ago        /bin/sh -c #(nop) COPY dir:25fadb737f3963795…   223MB\na9f846b4f00b        40 hours ago        /bin/sh -c npm install &&     npm cache clea…   1.66MB\ne50e35f227ce        40 hours ago        /bin/sh -c #(nop) COPY multi:a01b4a429dfd4d6…   64.3kB')])])]),t("p",[e._v("The image layers shown above are an inverse to the steps that were run as the images are built on top of each other step-by-step. For the second image down, we see a “COPY dir:25adb…”. This means the COPY instruction copied a directory and gave that directory a hash (sha256). If we were to build again and the content, and therefore hash, changed then we would not use the cache and run that instruction fresh. So, let’s loop back around and look at that initial Dockerfile to see why we had two copy instructions.")]),e._v(" "),t("div",{pre:!0,attrs:{class:"saber-highlight","data-lang":"sh"}},[t("pre",{pre:!0,attrs:{class:"saber-highlight-code language-sh"}},[t("code",{pre:!0,attrs:{class:"language-sh"}},[e._v('FROM node:10.7.0-alpine\n\nWORKDIR /usr/src/app\n\nCOPY package*.json /usr/src/app/\n\nRUN npm install && \\\n    npm cache clean -f\n\nCOPY . .\n\nCMD ["/bin/bash", "/usr/src/app/init"]')])])]),t("p",[e._v("For nodejs, package.json references the dependencies you want to install, and similarly, package-lock.json is metadata referring to the locked down dependency tree of what was previously installed. So above, package-lock.json would get a hash, if it changes we would run npm install from scratch and any instructions after that. If package-lock.json is the same as before, matching the cache, then we would use the cache and be eligible to use the cache for any instruction after that. "),t("em",[e._v("This means we can avoid a fresh npm install for every build by using the cache and saving on build time.")])]),e._v(" "),t("h3",{attrs:{id:"deploy-time"}},[e._v("Deploy time")]),e._v(" "),t("p",[e._v("Once we’ve built an image, we can push it to some central store like dockerhub to retrieve later. What we are really storing is each image layer and metadata on what image layers make up a complete image. This is nice as when we are deploying software and pulling in each layer, we can first check the file system to see if each layer is cached. Usually, you just bring in the top most layer which has a small change set. Here is an example of what you would see when inspecting the image.")]),e._v(" "),t("blockquote",[t("p",[e._v("$ docker inspect node:latest")])]),e._v(" "),t("div",{pre:!0,attrs:{class:"saber-highlight","data-lang":"sh"}},[t("pre",{pre:!0,attrs:{class:"saber-highlight-code language-sh"}},[t("code",{pre:!0,attrs:{class:"language-sh"}},[e._v('"RootFS": {\n  "Type": "layers",\n  "Layers": [\n    "sha256:73046094a9b835e443af1a9d736fcfc11a994107500e474d0abf399499ed280c",\n    "sha256:1f9f6c582bc2d0f7e70f6745e27d8e80b900cbb2cd1768b44021eb504f72d7de",\n    "sha256:0226750bc9fd9c86156d27378d9f243ffda55512222165b67c8595ea38490e13",\n    "sha256:31185621b9371561bb88ada0f5347ba85fc544cfc1c9417dccab790ddc64772b",\n    "sha256:e3357a4f00789a8203cfd07e51e77c691fdee07bb96e4bb1ce439b7ae9e77268",\n    "sha256:65b7d452c10466fe20133578e44d32cc4aa7b5daf5776b90765706579968e131",\n    "sha256:eac0035b5697e7a158849af0a08b4feb073d22319a6263c9219f1e13b36a8e45"\n  ]\n}')])])]),t("h2",{attrs:{id:"keep-it-light"}},[e._v("Keep it light")]),e._v(" "),t("p",[e._v("As you can see, Docker images are the files, aka the blueprint, that your containers start from. It is often easy to add an OS flavor of your liking and use the built-in package manager to add whatever you need. But, be careful, as building and deploying these images can grow over time. And, if you start out with a large image, you’ll only continue to pay down the road as build and deploy times start to grow. Let’s take a quick look at a couple popular base image choices:")]),e._v(" "),t("ul",[t("li",[t("em",[e._v("CentOS")]),e._v(" — 200 mb")]),e._v(" "),t("li",[t("em",[e._v("Ubuntu")]),e._v(" — 115 mb")]),e._v(" "),t("li",[t("em",[e._v("Alpine")]),e._v(" — 5 mb")])]),e._v(" "),t("p",[e._v("Alpine is based off of musl libc with a trimmed down set of binaries out of the box to keep it small. It also comes with it’s own apk package manager. This is a great choice for a base image.")]),e._v(" "),t("h2",{attrs:{id:"conclusion"}},[e._v("Conclusion")]),e._v(" "),t("p",[e._v("Understanding docker images and it’s corresponding layers is important. Optimize how you construct each layer to save you time during builds as well as deploys. Be sure to look at the output of your images history and see if there are any heavy layers that need updates.")]),e._v(" "),t("p",[e._v("For further reading, checkout:")]),e._v(" "),t("ul",[t("li",[t("saber-link",{attrs:{to:"https://docs.docker.com/v17.09/engine/userguide/storagedriver/imagesandcontainers/"}},[e._v("https://docs.docker.com/v17.09/engine/userguide/storagedriver/imagesandcontainers/")])],1),e._v(" "),t("li",[t("saber-link",{attrs:{to:"https://docs.docker.com/v17.09/engine/userguide/eng-image/dockerfile_best-practices"}},[e._v("https://docs.docker.com/v17.09/engine/userguide/eng-image/dockerfile_best-practices")])],1)])])}),[],!1,null,null,null);"function"==typeof n&&n(i);a.default=i.exports}}]);